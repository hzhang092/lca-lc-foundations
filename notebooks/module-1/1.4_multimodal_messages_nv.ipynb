{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74a0d45",
   "metadata": {},
   "source": [
    "## Text input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1efef",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d199fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ea1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.2-11b-vision-instruct\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a science fiction writer, create a capital city at the users request.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80786a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a fascinating request! As a science fiction writer, I'd be delighted to create a capital city on the Moon.\n",
      "\n",
      "Welcome to Luminaria, the shining capital of the Moon!\n",
      "\n",
      "Located in the vast, cratered expanse of the Moon's surface, Luminaria is a marvel of engineering and innovation. This futuristic city is nestled within the rim of a massive, ancient crater, its walls and structures glowing with a soft, ethereal light that seems almost otherworldly.\n",
      "\n",
      "**Geography and Climate:**\n",
      "Luminaria is situated in the lunar equatorial region, where the climate is relatively stable and temperate. The city's unique architecture allows it to harness and redirect the Moon's solar energy, providing a sustainable and reliable source of power. The atmosphere is thin, but the city's advanced life support systems maintain a comfortable pressure and oxygen level, making it habitable for humans and other species.\n",
      "\n",
      "**Districts and Landmarks:**\n",
      "\n",
      "1. **The Spire of Luminaria**: A towering, crystalline structure that serves as the city's iconic centerpiece. This magnificent spire is home to the Lunar Government and houses the Council of Elders, who govern the Moon's affairs.\n",
      "2. **The Lunar Gardens**: A lush, verdant oasis in the heart of the city, where advanced hydroponics and aeroponics systems allow for the cultivation of a wide variety of flora and fauna.\n",
      "3. **The Museum of Lunar History**: A vast, interactive repository of knowledge that chronicles the Moon's history, from its formation to the present day.\n",
      "4. **The Orbital Docking Bay**: A state-of-the-art facility that enables spacecraft to dock and refuel, facilitating trade, tourism, and scientific research with Earth and other celestial bodies.\n",
      "5. **The Lunar Academy**: A prestigious institution of higher learning, where students from across the solar system come to study the Moon's unique environment, astronomy, and advanced technologies.\n",
      "\n",
      "**Transportation and Infrastructure:**\n",
      "Luminaria is connected to the rest of the Moon by a network of elevated walkways, monorails, and vacuum-sealed tubes, allowing for efficient and safe transportation. The city's advanced transportation systems also include personal grav-tubes, which enable citizens to travel quickly and comfortably throughout the city.\n",
      "\n",
      "**Innovations and Features:**\n",
      "\n",
      "1. **Gravity Manipulation**: Luminaria's unique architecture allows for localized gravity manipulation, creating areas with varying gravitational forces, making it easier for humans and other species to move around.\n",
      "2. **Atmospheric Processors**: Advanced systems that maintain a stable atmosphere, ensuring a healthy and comfortable environment for all inhabitants.\n",
      "3. **Energy Harvesting**: The city's structures and infrastructure are designed to harness and convert the Moon's solar and lunar energy into a clean, sustainable source of power.\n",
      "\n",
      "Luminaria, the shining capital of the Moon, is a beacon of hope and progress, a testament to human ingenuity and the boundless potential of space exploration.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"What is the capital of The Moon?\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9205f9",
   "metadata": {},
   "source": [
    "## Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b3da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='nvidia/nvclip' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='meta/llama-3.2-11b-vision-instruct' model_type='vlm' client='ChatNVIDIA' endpoint='https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-11b-vision-instruct/chat/completions' aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='google/gemma-3n-e4b-it' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='mistralai/mistral-small-3.1-24b-instruct-2503' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='mistralai/ministral-14b-instruct-2512' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='meta/llama-4-maverick-17b-128e-instruct' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='nvidia/llama-3.1-nemotron-nano-vl-8b-v1' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='microsoft/phi-4-multimodal-instruct' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='google/gemma-3n-e2b-it' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='mistralai/mistral-large-3-675b-instruct-2512' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='meta/llama-3.2-90b-vision-instruct' model_type='vlm' client='ChatNVIDIA' endpoint='https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-90b-vision-instruct/chat/completions' aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='meta/llama-4-scout-17b-16e-instruct' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='microsoft/phi-3.5-vision-instruct' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n",
      "id='mistralai/mistral-medium-3-instruct' model_type='vlm' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=False supports_structured_output=False supports_thinking=False thinking_prefix=None no_thinking_prefix=None thinking_param_enable=None thinking_param_disable=None base_model=None\n"
     ]
    }
   ],
   "source": [
    "tool_models = [model for model in ChatNVIDIA.get_available_models() if model.model_type == 'vlm']\n",
    "for elem in tool_models:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e6e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113a919e56fa45388b8cbf56cc250e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.png', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = FileUpload(accept='.png', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f71141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'name': 'Screenshot 2025-10-07 212432.png', 'type': 'image/png', 'size': 246811, 'content': <memory at 0x000001697F289D80>, 'last_modified': datetime.datetime(2025, 10, 8, 1, 24, 32, 850000, tzinfo=datetime.timezone.utc)},)\n"
     ]
    }
   ],
   "source": [
    "print(uploader.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21debb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Get the first (and only) uploaded file dict\n",
    "uploaded_file = uploader.value[0]\n",
    "\n",
    "# This is a memoryview\n",
    "content_mv = uploaded_file[\"content\"]\n",
    "\n",
    "# Convert memoryview -> bytes\n",
    "img_bytes = bytes(content_mv)  # or content_mv.tobytes()\n",
    "\n",
    "# compress the image\n",
    "with Image.open(io.BytesIO(img_bytes)) as img:\n",
    "    img = img.convert(\"RGB\")\n",
    "    img.thumbnail((1024, 1024))  # optional resize for smaller payload\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format=\"JPEG\", quality=70, optimize=True)\n",
    "    img_bytes = buf.getvalue()\n",
    "\n",
    "# Now base64 encode\n",
    "img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604afd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a cartoon-style illustration of a yellow caravan with two people inside, set against a blue sky with white clouds. The caravan is positioned on a hill, with a tree to its left and a house in the background. The title \"CARAVAN\" is prominently displayed in large white letters, with \"SAND Witch\" written in smaller text underneath.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Caravan:** Yellow in color, with a large tire on the back and a smaller one on the front.\n",
      "* **People:** Two individuals are visible inside the caravan, one sitting on top and the other standing at the side.\n",
      "* **Background:** A blue sky with white clouds, a tree to the left of the caravan, and a house in the distance.\n",
      "* **Title:** \"CARAVAN\" in large white letters, with \"SAND Witch\" written in smaller text underneath.\n",
      "* **Border:** A gray border surrounds the image, with a red box containing Chinese characters in the top-left corner.\n",
      "\n",
      "**Overall Impression:**\n",
      "\n",
      "The image appears to be a promotional graphic for a science fiction story or game, featuring a unique and colorful caravan as the central element. The use of a blue sky and white clouds creates a sense of optimism and adventure, while the presence of a tree and a house adds a touch of realism to the scene. The title \"CARAVAN\" and the subtitle \"SAND Witch\" suggest that the story may involve themes of travel, exploration, and possibly magic or fantasy elements.\n"
     ]
    }
   ],
   "source": [
    "image_data_url = f\"data:image/png; base64,{img_b64}\"\n",
    "\n",
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Tell me about this image.\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [multimodal_question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262fb1c",
   "metadata": {},
   "source": [
    "## Audio input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04613a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models likely to support audio inputs:\n"
     ]
    }
   ],
   "source": [
    "# 1. Fetch all available models from the NVIDIA endpoint\n",
    "all_models = ChatNVIDIA.get_available_models()\n",
    "\n",
    "# 2. Filter for likely audio models based on ID and type conventions\n",
    "audio_models = [\n",
    "    model.id for model in all_models \n",
    "    if \"asr\" in model.model_type.lower() \n",
    "    or \"audio\" in model.model_type.lower() \n",
    "    or \"parakeet\" in model.id.lower()\n",
    "]\n",
    "\n",
    "print(\"Models likely to support audio inputs:\")\n",
    "for model_id in audio_models:\n",
    "    print(f\"- {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import base64\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Recording settings\n",
    "duration = 5  # seconds\n",
    "sample_rate = 44100\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "# Progress bar for the duration\n",
    "for _ in tqdm(range(duration * 10)):   # update 10Ã— per second\n",
    "    time.sleep(0.1)\n",
    "sd.wait()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Write WAV to an in-memory buffer\n",
    "buf = io.BytesIO()\n",
    "write(buf, sample_rate, audio)\n",
    "wav_bytes = buf.getvalue()\n",
    "\n",
    "aud_b64 = base64.b64encode(wav_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model='gpt-4o-audio-preview',\n",
    ")\n",
    "\n",
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Tell me about this audio file\"},\n",
    "    {\"type\": \"audio\", \"base64\": aud_b64, \"mime_type\": \"audio/wav\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [multimodal_question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3208a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twelve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
