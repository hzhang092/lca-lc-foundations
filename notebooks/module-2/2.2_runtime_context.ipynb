{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00525f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dbd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ColourContext:\n",
    "    favourite_colour: str = \"blue\"\n",
    "    least_favourite_colour: str = \"yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03be72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "model = ChatNVIDIA(model = \"meta/llama-3.3-70b-instruct\", temperature=0.2)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    context_schema=ColourContext  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec82bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e923d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='3ff04ba8-1eff-41a3-9aa9-ccccf880df6e'),\n",
      "              AIMessage(content=\"I don't have any information about your personal preferences, including your favourite colour. I'm a large language model, I don't have the ability to know or remember individual users' preferences or personal details. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to share your favourite colour with me, I'd be happy to chat with you about it!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"I don't have any information about your personal preferences, including your favourite colour. I'm a large language model, I don't have the ability to know or remember individual users' preferences or personal details. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to share your favourite colour with me, I'd be happy to chat with you about it!\", 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None, 'token_usage': {'prompt_tokens': 41, 'total_tokens': 129, 'completion_tokens': 88, 'prompt_tokens_details': None}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='lc_run--019c8d63-4a38-7fe0-9574-2f2396d3a90a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 88, 'total_tokens': 129}, role='assistant')]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24874360",
   "metadata": {},
   "source": [
    "## Accessing Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dca527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the favourite colour of the user\"\"\"\n",
    "    return runtime.context.favourite_colour\n",
    "\n",
    "@tool\n",
    "def get_least_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the least favourite colour of the user\"\"\"\n",
    "    return runtime.context.least_favourite_colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce743296",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_favourite_colour, get_least_favourite_colour],\n",
    "    context_schema=ColourContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07e137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\anaconda\\envs\\twelve\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=ColourContext(favourite_c...vourite_colour='yellow'), input_type=ColourContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='83669a42-c35d-483b-9057-36e9d9bcb615'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-89d1e9ef9aa21c7d', 'type': 'function', 'function': {'name': 'get_favourite_colour', 'arguments': '{}'}}]}, response_metadata={'role': 'assistant', 'content': None, 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-89d1e9ef9aa21c7d', 'type': 'function', 'function': {'name': 'get_favourite_colour', 'arguments': '{}'}}], 'reasoning': None, 'reasoning_content': None, 'token_usage': {'prompt_tokens': 277, 'total_tokens': 298, 'completion_tokens': 21, 'prompt_tokens_details': None}, 'finish_reason': 'tool_calls', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='lc_run--019c8d6b-676f-7a42-ad78-98564ad404bd-0', tool_calls=[{'name': 'get_favourite_colour', 'args': {}, 'id': 'chatcmpl-tool-89d1e9ef9aa21c7d', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 277, 'output_tokens': 21, 'total_tokens': 298}, role='assistant'),\n",
      "              ToolMessage(content='blue', name='get_favourite_colour', id='dcee6cfc-1bae-413f-841a-7a7d9411a6ad', tool_call_id='chatcmpl-tool-89d1e9ef9aa21c7d'),\n",
      "              AIMessage(content='Your favourite colour is blue.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your favourite colour is blue.', 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None, 'token_usage': {'prompt_tokens': 308, 'total_tokens': 315, 'completion_tokens': 7, 'prompt_tokens_details': None}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='lc_run--019c8d6b-6aa8-7c82-9627-e33056542fe2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 308, 'output_tokens': 7, 'total_tokens': 315}, role='assistant')]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f68fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\anaconda\\envs\\twelve\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=ColourContext(favourite_c...vourite_colour='yellow'), input_type=ColourContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='f389c1f3-ddf7-4299-81f3-194bf7a81ee0'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-908a372b79497644', 'type': 'function', 'function': {'name': 'get_favourite_colour', 'arguments': '{}'}}]}, response_metadata={'role': 'assistant', 'content': None, 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-908a372b79497644', 'type': 'function', 'function': {'name': 'get_favourite_colour', 'arguments': '{}'}}], 'reasoning': None, 'reasoning_content': None, 'token_usage': {'prompt_tokens': 277, 'total_tokens': 298, 'completion_tokens': 21, 'prompt_tokens_details': None}, 'finish_reason': 'tool_calls', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='lc_run--019c8d75-4177-75d3-bb55-fe66c5ded827-0', tool_calls=[{'name': 'get_favourite_colour', 'args': {}, 'id': 'chatcmpl-tool-908a372b79497644', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 277, 'output_tokens': 21, 'total_tokens': 298}, role='assistant'),\n",
      "              ToolMessage(content='green', name='get_favourite_colour', id='8a876be1-8ab4-4b4b-82bc-72c9b92decfe', tool_call_id='chatcmpl-tool-908a372b79497644'),\n",
      "              AIMessage(content='Your favourite colour is green.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your favourite colour is green.', 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None, 'token_usage': {'prompt_tokens': 308, 'total_tokens': 315, 'completion_tokens': 7, 'prompt_tokens_details': None}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='lc_run--019c8d75-44c8-7711-9a95-7eff5ab3cb65-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 308, 'output_tokens': 7, 'total_tokens': 315}, role='assistant')]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext(favourite_colour=\"green\")\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4adca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twelve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
